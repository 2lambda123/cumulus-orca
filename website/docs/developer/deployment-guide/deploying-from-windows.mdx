---
id: deploying-from-windows
title: Deploy from Windows
description: A concrete set of instructions on deploying from Windows to create a test environment.
---

import useBaseUrl from '@docusaurus/useBaseUrl';

Deploying Cumulus, CumulusDashboard, and Orca from Windows brings some additional challenges.
The goal of this page is to provide a set of modified instructions to get around common errors.

### Notes
- Choose a PREFIX that will identify your installation when in AWS. This string will be used throughout deployment.
- Connect to the NASA VPN to be able to connect to AWS.
:::warning
The VPN drastically slows down Terraform operations, and limits what documentation can be viewed. Switch off when applicable.
:::
- Commands here will use ```us-west-2``` for region because of the current state of our sandbox. Replace consistently as needed.
    - Make sure any operations in AWS are done under the correct region.

## Application
This application will be used in future steps to authenticate users.
- Go to https://uat.urs.earthdata.nasa.gov/profile
- Applications -> My Applications
- Create a new Application
    - Application ID: ```prefix_cumulus```
    - Application Name ```Prefix Cumulus```
    - Application Type: ```OAuth 2```
    - Redirect URL: todo

## Initial Setup
- Follow the [deployment environment setup instructions](setting-up-deployment-environment.mdx).
    - You may need to install Terraform manually.
    - Only configure the default profile.
    - Keep the access keys in plain-text. You will need to run ```aws configure``` in multiple environments.
- Create an AWS Key Value Pair by following  [the AWS instructions](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html#having-ec2-create-your-key-pair).
    - Choose the '.pem' format.
    - Naming convention is PREFIX-key-pair.pem
- Create buckets in the same OU and region as the other installations.
    - Same OU and region would not be ideal for a real backup system, but is generally sufficient for testing.
    - Required buckets are PREFIX-tf-state, PREFIX-glacier, PREFIX-internal, PREFIX-private, PREFIX-protected, PREFIX-public, and PREFIX-orca
    :::tip
    An example command for creating a bucket in us-west-2. Remember to run ```aws configure``` first.
    ```commandline
    aws s3api create-bucket --bucket PREFIX-tf-state --profile default --region us-west-2 --create-bucket-configuration "LocationConstraint=us-west-2"
    ```

## [Cumulus](https://nasa.github.io/cumulus/docs/deployment/deployment-readme)
- Run
```commandline
aws dynamodb create-table --table-name PREFIX-tf-locks --attribute-definitions AttributeName=LockID,AttributeType=S --key-schema AttributeName=LockID,KeyType=HASH --billing-mode PAY_PER_REQUEST --region us-west-2
```
- Run
```commandline
aws s3api put-bucket-versioning --bucket PREFIX-tf-state --versioning-configuration Status=Enabled
```

:::warning
We presently have no instructions for creating a VPC, Subnet, Security Group, or PostgreSQL database.
Borrow them from an existing setup.
:::
- Go to [this repo](https://git.earthdata.nasa.gov/projects/ORCA/repos/cumulus-orca-template-deploy/browse) and download.
- Unzip.
- Remove the '.example' on terraform.tf and terraform.tfvars files in data-persistence-tf, cumulus-tf, and cumulus-tf\extensions\orca-app.
- In each terraform.tf and terraform.tfvars, use your own prefix, region, and subnet ids.
:::warning
The region and prefix are not always in simple variables. Do a global search for 'PREFIX' and 'us-east-1'.
:::
:::warning
Only use the non-lambda subnet id in the data-persistence-tf/terraform.tfvars. In cumulus-tf use both.
:::
:::warning
Overwrite the 'orca-sandbox' in "orca-sandbox-tf-locks" with your prefix as well.
:::
- In cumulus-tf/terraform.tfvars
    - Replace 12345 in permissions_boundary_arn with the Account Id.
    <img alt="Location of Account Id" src={useBaseUrl('img/aws-account-id.PNG')} />
    - Add to the buckets:
```
default_orca = {
   name = "prefix-orca"
   type = "orca"
  },
  provider = {
    name = "orca-sandbox-s3-provider"
    type = "provider"
}
```
:::warning
We do not have instructions for creating the provider bucket.
:::
-
    - Replace the ```cumulus_message_adapter_lambda_layer_version_arn``` with a valid one.

:::warning
Process for finding the correct arn is not documented.
:::
-
    - Set the ```ecs_cluster_instance_image_id``` to ```""```
    - ```ecs_cluster_instance_subnet_ids``` and ```lambda_subnet_ids``` should have the same two values.
    - Set the ```vpc_id``` to the id of your borrowed VPC.
    - Set the cmr values to values of your choice, baring ```cmr_environment```
    - Set ```urs_client_id``` and ```urs_client_password``` to the values from your created application.
    - Add an extra property ```urs_url = "https://uat.urs.earthdata.nasa.gov"```
    - Add your username to the ```api_users```
    - Set ```token_secret``` to a value of your choice.
    - Comment out the ```archive_api_port``` property and value.
    - Uncomment the ```key_name property``` and set the value to ```prefix-key-pair```
    - Add this section to the bottom of the file:
```
## ORCA Configuration
subnet_ids           = [Same two subnet ids as above]
database_port        = "5432"
database_name        = "disaster_recovery"
database_app_user    = "druser"
database_app_user_pw = "my_app-user-pw"
database_user_pw     = "super-secur3-p4ssw0rd"
postgres_user_pw     = "super-secur3-p4ssw0rd"
ddl_dir              = "ddl/"
drop_database        = "False"
platform             = "AWS"

## Default ORCA S3 Glacier bucket to use
orca_default_bucket = "prefix-orca"
aws_profile = "default"
```

:::warning
The instructions in the tfvars file suggest swapping '12345' with your account ID. This may not work, depending on how your dependencies such as the cumulus_message_adapter_lambda_layer_version_arn were set up.
:::

- In extensions_variables.tf, add:
```
variable "orca_default_bucket" {
  type        = string
  description = "Default ORCA S3 Glacier bucket to use."
}
```
- In extensions.tf, modify the ORCA Module.
    - Set the ```source``` to point to your ```cumulus-orca/modules``` folder. Note that this folder must be in the same directory as (or a subdirectory of) your downloaded repo. If done correctly, will look like ```source = "./../../cumulus-orca/modules"```
    - Remove the ```ecs_cluster_instance_subnet_ids```, ```database_name```, ```database_app_user```, and ```drop_database```  properties.
    - Add ```lambda_subnet_ids = var.lambda_subnet_ids```, ```orca_default_bucket  = var.orca_default_bucket```, and ```system_bucket = var.system_bucket```
    - As a best practice, add the property ```tags = var.tags```
- Go to https://github.com/asfadmin/CIRRUS-core/blob/master/Dockerfile and download the file to the same folder as your downloaded repo and orca folder.
:::tip
Make sure that no extension is added.
:::
- Open a commandline in the same folder.
    - Run ```docker build -t orca .``` and ```docker run -it --rm -v pathToYourFolder:/CIRRUS-core orca /bin/bash```
    - The commandline should now be inside a docker container.
```bash
cd cumulus-orca-template-deploy/data-persistence-tf/
aws configure
terraform init
terraform plan
terraform apply
cd ../cumulus-tf
terraform init
terraform plan
terraform apply
```

## Orca
- Follow [Create the ORCA Archive Bucket](creating-orca-glacier-bucket.md)
